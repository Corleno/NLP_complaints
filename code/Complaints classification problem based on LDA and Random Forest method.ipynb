{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complaints classification problem using LDA and Random Forest method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook describes an interesting approach to classify the financial complaints to specific issues. Generally, it contains three parts. First, we prepocess the complaints using embedding approaches including removing stop words and stemming words. Then we using embedding method to vercterize every complaints and use the online LDA methods to reduce the dimension. Finally, we use random forest method to deal with the standard classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - <a href='#1'>1. Import packages</a>  \n",
    " - <a href='#2'>2. Preprocessing</a>\n",
    " - <a href='#3'>3. LDA</a>\n",
    " - <a href='#4'>4. Random Forest</a>\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='1'>1. Import packages</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from textblob import TextBlob\n",
    "from nltk.corpus import stopwords\n",
    "from textblob.sentiments import NaiveBayesAnalyzer\n",
    "import nltk\n",
    "import itertools\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='2'>2. Preprossing</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define two functions. One is to convert unstructure colnames to readable colnames. The other is to select the complement data with respect to their traits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pythonize_colnames(df):\n",
    "    df.columns = list(map(lambda each:re.sub('[^0-9a-zA-Z]+', '_', each).lower(), df.columns))\n",
    "    return (df)\n",
    "def select_complete_data(df, traits):\n",
    "    df = df.dropna(subset = traits)\n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All traits in the datasets are shown below. We select 7 import treats as \"Data received date\", \"Product\", \"Sub-product\", \"Issue\", \"Sub-issue\", \"Consumer complaint narrative\" and \"Complaint ID\". And we rebuild a dataframe called df_complaints_full. Also the head of this dataframe is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traits are: Index(['Date received', 'Product', 'Sub-product', 'Issue', 'Sub-issue',\n",
      "       'Consumer complaint narrative', 'Company public response', 'Company',\n",
      "       'State', 'ZIP code', 'Tags', 'Consumer consent provided?',\n",
      "       'Submitted via', 'Date sent to company', 'Company response to consumer',\n",
      "       'Timely response?', 'Consumer disputed?', 'Complaint ID'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_received</th>\n",
       "      <th>product</th>\n",
       "      <th>sub_product</th>\n",
       "      <th>issue</th>\n",
       "      <th>sub_issue</th>\n",
       "      <th>consumer_complaint_narrative</th>\n",
       "      <th>complaint_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03/12/2014</td>\n",
       "      <td>Mortgage</td>\n",
       "      <td>Other mortgage</td>\n",
       "      <td>Loan modification,collection,foreclosure</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>759217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/01/2016</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Incorrect information on credit report</td>\n",
       "      <td>Account status</td>\n",
       "      <td>I have outdated information on my credit repor...</td>\n",
       "      <td>2141773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10/17/2016</td>\n",
       "      <td>Consumer Loan</td>\n",
       "      <td>Vehicle loan</td>\n",
       "      <td>Managing the loan or lease</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I purchased a new car on XXXX XXXX. The car de...</td>\n",
       "      <td>2163100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>06/08/2014</td>\n",
       "      <td>Credit card</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bankruptcy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>885638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>09/13/2014</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>Credit card</td>\n",
       "      <td>Communication tactics</td>\n",
       "      <td>Frequent or repeated calls</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1027760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  date_received           product     sub_product  \\\n",
       "0    03/12/2014          Mortgage  Other mortgage   \n",
       "1    10/01/2016  Credit reporting             NaN   \n",
       "2    10/17/2016     Consumer Loan    Vehicle loan   \n",
       "3    06/08/2014       Credit card             NaN   \n",
       "4    09/13/2014   Debt collection     Credit card   \n",
       "\n",
       "                                      issue                   sub_issue  \\\n",
       "0  Loan modification,collection,foreclosure                         NaN   \n",
       "1    Incorrect information on credit report              Account status   \n",
       "2                Managing the loan or lease                         NaN   \n",
       "3                                Bankruptcy                         NaN   \n",
       "4                     Communication tactics  Frequent or repeated calls   \n",
       "\n",
       "                        consumer_complaint_narrative  complaint_id  \n",
       "0                                                NaN        759217  \n",
       "1  I have outdated information on my credit repor...       2141773  \n",
       "2  I purchased a new car on XXXX XXXX. The car de...       2163100  \n",
       "3                                                NaN        885638  \n",
       "4                                                NaN       1027760  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_FOLDER = os.path.join('..', 'data')\n",
    "df_consumer_complaints = pd.read_csv(os.path.join(DATA_FOLDER, 'complaints.csv'))\n",
    "print (\"Traits are: {}\".format(df_consumer_complaints.columns))\n",
    "df_complaints_full = df_consumer_complaints[['Date received','Product', 'Sub-product', 'Issue', 'Sub-issue',\n",
    "       'Consumer complaint narrative', 'Complaint ID']]\n",
    "# pythonize the column names\n",
    "df_complaints_full = pythonize_colnames(df_complaints_full)\n",
    "df_complaints_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We select the data whose sub-product is \"Checking account\" and rebuilt the corresponding dataframe named as df_checking_ac_complaints_complete. You can definitely choose other sub-dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only for checking account product \n",
    "df_checking_ac_complaints = df_complaints_full.loc[df_complaints_full['sub_product'] == 'Checking account']\n",
    "traits = ['consumer_complaint_narrative', 'issue', 'sub_issue']\n",
    "df_checking_ac_complaints_complete = select_complete_data(df_checking_ac_complaints, traits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='3'>3. LDA </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will embedding all narrative into vectors and use online LDA method to reduce the dimension of those vecters as features in the next step. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the word dataset and stop word dataset named as words and stop seperately. The stop word dataset includes the words that are not meaningful in the narratives. Im order to improve the performance of the classification, we need to tune the stop dataset!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set words and stopwords\n",
    "words = set(nltk.corpus.words.words())\n",
    "stop = stopwords.words('english')\n",
    "stop.extend(['money', 'go', 'without', 'told', 'day', 'one', 'bank', 'account', 'wells fargo', 'wells', 'fargo', 'america','bank of america', 'boa', 'chase', 'citi', 'citibank', 'citi bank', 'suntrust', 'huntington bank', 'pnc', 'citigold', 'navy federal credit union', 'usaa', 'pnc bank', 'first national bank', 'us bank', 'us', 'would'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose the 1000 meaningful words as baisc features. There are some contraints for those words.\n",
    "First, those words should appear at least twice in the dataset. \n",
    "Second, we consider the 3-gram model. It suggests that those word may comprise at most three grams such as \"well fargo bank\", because some of those n-gram words are very important.  \n",
    "Third, each gram should be stemmed. \n",
    "Then we randomly choose 85% dataset as trainning dataset and remainning 15% as testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_features = 1000\n",
    "# Randomly split training set and testing set\n",
    "X_train, X_test = train_test_split(df_checking_ac_complaints_complete[['consumer_complaint_narrative', 'issue', 'sub_issue']], test_size=0.15, random_state=42)\n",
    "\n",
    "# print (X_train.head())\n",
    "# print (X_test.head())\n",
    "\n",
    "# LDA can only use raw term counts for LDA because it is a probabilistic graphical model\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2, ngram_range=(1,3), max_features=no_features, stop_words=frozenset(stop))\n",
    "# Preprocess for narratives including stemming\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "p_stemmer = PorterStemmer()\n",
    "narratives_train = X_train['consumer_complaint_narrative'].map(lambda x: \" \".join(re.sub(r'([^a-zA-Z ]+?)', '', \" \".join(p_stemmer.stem(w) for w in nltk.wordpunct_tokenize(x) if w.lower() in words and not w.lower() in stop)).split()))\n",
    "narratives_test = X_test['consumer_complaint_narrative'].map(lambda x: \" \".join(re.sub(r'([^a-zA-Z ]+?)', '', \" \".join(p_stemmer.stem(w) for w in nltk.wordpunct_tokenize(x) if w.lower() in words and not w.lower() in stop)).split()))\n",
    "\n",
    "# print (narratives)\n",
    "tf_train = tf_vectorizer.fit_transform(narratives_train)\n",
    "tf_test = tf_vectorizer.transform(narratives_test)\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "# print (tf_feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part is optimal. It is used to select the optimal number of topics in LDA model based on the perplexity of the test dataset. However, it doesn't make much sence due to the one paper form Chang 2009."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rui/.local/lib/python3.5/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n",
      "/home/rui/.local/lib/python3.5/site-packages/sklearn/decomposition/online_lda.py:812: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if doc_topic_distr != 'deprecated':\n",
      "/home/rui/.local/lib/python3.5/site-packages/sklearn/decomposition/online_lda.py:816: DeprecationWarning: Argument 'doc_topic_distr' is deprecated and is being ignored as of 0.19. Support for this argument will be removed in 0.21.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 : 628.3283111165834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rui/.local/lib/python3.5/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n",
      "/home/rui/.local/lib/python3.5/site-packages/sklearn/decomposition/online_lda.py:816: DeprecationWarning: Argument 'doc_topic_distr' is deprecated and is being ignored as of 0.19. Support for this argument will be removed in 0.21.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 : 643.5687211523843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rui/.local/lib/python3.5/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n",
      "/home/rui/.local/lib/python3.5/site-packages/sklearn/decomposition/online_lda.py:816: DeprecationWarning: Argument 'doc_topic_distr' is deprecated and is being ignored as of 0.19. Support for this argument will be removed in 0.21.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 : 655.6841065260987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rui/.local/lib/python3.5/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n",
      "/home/rui/.local/lib/python3.5/site-packages/sklearn/decomposition/online_lda.py:816: DeprecationWarning: Argument 'doc_topic_distr' is deprecated and is being ignored as of 0.19. Support for this argument will be removed in 0.21.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 : 660.5185357249626\n"
     ]
    }
   ],
   "source": [
    "for i in range(8, 12):\n",
    "    lda = LatentDirichletAllocation(n_topics=i, max_iter=5, learning_method='online', learning_offset=64.,random_state=0).fit(tf_train)\n",
    "    train_gamma = lda.transform(tf_test)\n",
    "    train_perplexity = lda.perplexity(tf_test, train_gamma)\n",
    "    print(str(i), ':', str(train_perplexity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We select the LDA model with 10 topics. And train the LDA model using training dataset and tranform training data and testing data to vectors as lda_D_train and lda_D_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rui/.local/lib/python3.5/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "lda = LatentDirichletAllocation(n_topics=10, max_iter=5, learning_method='online', learning_offset=64.,random_state=0).fit(tf_train)\n",
    "# words per topic\n",
    "lda_T = lda.components_\n",
    "# topics per document_\n",
    "lda_D_train = lda.transform(tf_train)\n",
    "lda_D_test = lda.transform(tf_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we choose 10 topics, we select the top 5 most likely words in each topics. You can find some topics are meaningful. For example, the second topic \"fraud,inform,branch,report,person\" suggests that this complaint may relate to the fraud. and the third topic \"block,need,simpl,discov,consum\", suggests that this complaint may related to the block of account. However, the 8th topic \"get,back,said,call,tri\" seems to be used to state a fact, which doesn't provided much inforamation directly.\n",
    "However, if we jointly consider the information of all topics, it will give me amazing information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deposit,direct,bonu,branch,receiv\n",
      "fraud,inform,branch,report,person\n",
      "block,need,simpl,discov,consum\n",
      "receiv,letter,provid,inform,complaint\n",
      "credit,credit card,feder,card,navi\n",
      "check,fund,hold,transfer,avail\n",
      "card,claim,debit,debit card,transact\n",
      "get,back,said,call,tri\n",
      "overdraft,fee,balanc,charg,transact\n",
      "close,pay,balanc,fee,time\n"
     ]
    }
   ],
   "source": [
    "no_top_words = 5\n",
    "for topic_idx, topic in enumerate(lda_T):\n",
    "    print (\",\".join([tf_feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This is another optimal part. It is used to provide the complaints where it has high probability for certain topic. As I stated before, if we only care about certain topic, it cannot provide use sufficient information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def display_topics(H, W, feature_names, documents, no_top_words, no_top_documents):\n",
    "#     for topic_idx, topic in enumerate(H):\n",
    "#         print (\"Topic %d:\" % (topic_idx))\n",
    "#         print (\" \".join([feature_names[i]\n",
    "#                         for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "#         top_doc_indices = np.argsort( W[:,topic_idx] )[::-1][0:no_top_documents]\n",
    "#         for doc_index in top_doc_indices:\n",
    "#             print (documents.iloc[doc_index,])\n",
    "\n",
    "# lda_W = lda.transform(tf)\n",
    "# lda_H = lda.components_\n",
    "\n",
    "# no_top_words = 5\n",
    "# no_top_documents = 2\n",
    "# display_topics(lda_H, lda_W, tf_feature_names, X_train['consumer_complaint_narrative'], no_top_words, no_top_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide the top 5 high-probability words for each topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct_topics = {\"0\": \"deposit,direct,bonu,branch,receiv\",\n",
    "\"1\": \"fraud,inform,branch,report,person\",\n",
    "\"2\": \"block,need,simpl,discov,consum\",\n",
    "\"3\": \"receiv,letter,provid,inform,complaint\",\n",
    "\"4\": \"credit,credit card,feder,card,navi\",\n",
    "\"5\": \"check,fund,hold,transfer,avail\",\n",
    "\"6\": \"card,claim,debit,debit card,fraud\",\n",
    "\"7\": \"get,back,said,call,tri\",\n",
    "\"8\": \"overdraft,fee,balanc,charg,transact\",\n",
    "\"9\": \"close,pay,balanc,fee,time\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions using single topic information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we only use a single opic information for prediction, the results doesn't make much sense. The results are shown as below. There, we use compute the polarity and subjectivity traits for each complaints. Thoes two complaints could be considered in the following random forest algorithm. For simplicity, I didn't consider these two traits. If you are interested in both traits you can simply put them as feature in the random forest algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>consumer_complaint_narrative</th>\n",
       "      <th>issue</th>\n",
       "      <th>sub_issue</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>849900</th>\n",
       "      <td>USBank allowed my ex husband to fraudulently o...</td>\n",
       "      <td>Opening an account</td>\n",
       "      <td>Account opened as a result of fraud</td>\n",
       "      <td>fraud,inform,branch,report,person</td>\n",
       "      <td>-0.069585</td>\n",
       "      <td>0.367512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967968</th>\n",
       "      <td>My husband and I have had a joint account at P...</td>\n",
       "      <td>Problem caused by your funds being low</td>\n",
       "      <td>Overdrafts and overdraft fees</td>\n",
       "      <td>fraud,inform,branch,report,person</td>\n",
       "      <td>0.016532</td>\n",
       "      <td>0.167742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907684</th>\n",
       "      <td>My personal check was refused at XXXX XXXX eve...</td>\n",
       "      <td>Managing an account</td>\n",
       "      <td>Problem making or receiving payments</td>\n",
       "      <td>get,back,said,call,tri</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971822</th>\n",
       "      <td>It 's beyond any human being to imagine the to...</td>\n",
       "      <td>Closing an account</td>\n",
       "      <td>Funds not received from closed account</td>\n",
       "      <td>get,back,said,call,tri</td>\n",
       "      <td>0.028432</td>\n",
       "      <td>0.452938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938113</th>\n",
       "      <td>I lodged a complaint few days back to CFPB. Th...</td>\n",
       "      <td>Managing an account</td>\n",
       "      <td>Banking errors</td>\n",
       "      <td>deposit,direct,bonu,branch,receiv</td>\n",
       "      <td>-0.111111</td>\n",
       "      <td>0.355556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             consumer_complaint_narrative  \\\n",
       "849900  USBank allowed my ex husband to fraudulently o...   \n",
       "967968  My husband and I have had a joint account at P...   \n",
       "907684  My personal check was refused at XXXX XXXX eve...   \n",
       "971822  It 's beyond any human being to imagine the to...   \n",
       "938113  I lodged a complaint few days back to CFPB. Th...   \n",
       "\n",
       "                                         issue  \\\n",
       "849900                      Opening an account   \n",
       "967968  Problem caused by your funds being low   \n",
       "907684                     Managing an account   \n",
       "971822                      Closing an account   \n",
       "938113                     Managing an account   \n",
       "\n",
       "                                     sub_issue  \\\n",
       "849900     Account opened as a result of fraud   \n",
       "967968           Overdrafts and overdraft fees   \n",
       "907684    Problem making or receiving payments   \n",
       "971822  Funds not received from closed account   \n",
       "938113                          Banking errors   \n",
       "\n",
       "                                    Topic  Polarity  Subjectivity  \n",
       "849900  fraud,inform,branch,report,person -0.069585      0.367512  \n",
       "967968  fraud,inform,branch,report,person  0.016532      0.167742  \n",
       "907684             get,back,said,call,tri -0.133333      0.333333  \n",
       "971822             get,back,said,call,tri  0.028432      0.452938  \n",
       "938113  deposit,direct,bonu,branch,receiv -0.111111      0.355556  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test['Topic'] = [dct_topics[str(lda_D_test[idx, :].argmax())] for idx in range(0, X_test.shape[0])]\n",
    "X_test['Polarity'] = [TextBlob(doc).sentiment[0] for doc in list(X_test['consumer_complaint_narrative'])]\n",
    "X_test['Subjectivity'] = [TextBlob(doc).sentiment[1] for doc in list(X_test['consumer_complaint_narrative'])]\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore the issues and subissues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We simply group issues and sub-issues based on the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "issue\n",
       "Closing an account                                                                   540\n",
       "Credit monitoring or identity theft protection services                                2\n",
       "Improper use of your report                                                            6\n",
       "Incorrect information on your report                                                  19\n",
       "Managing an account                                                                 2616\n",
       "Opening an account                                                                   565\n",
       "Problem caused by your funds being low                                               570\n",
       "Problem with a credit reporting company's investigation into an existing problem       3\n",
       "Problem with a lender or other company charging your account                         548\n",
       "Unable to get your credit report or credit score                                       2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.groupby(['issue']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sub_issue\n",
       "Account information incorrect                                                              4\n",
       "Account opened as a result of fraud                                                       92\n",
       "Account status incorrect                                                                   5\n",
       "Banking errors                                                                           328\n",
       "Billing dispute for services                                                               1\n",
       "Bounced checks or returned payments                                                       43\n",
       "Can't close your account                                                                  98\n",
       "Can't stop withdrawals from your account                                                  61\n",
       "Cashing a check                                                                           98\n",
       "Company closed your account                                                              294\n",
       "Confusing or missing disclosures                                                          28\n",
       "Credit inquiries on your report that you don't recognize                                   1\n",
       "Deposits and withdrawals                                                                 748\n",
       "Didn't receive terms that were advertised                                                263\n",
       "Difficulty submitting a dispute or getting information about a dispute over the phone      1\n",
       "Fee problem                                                                              356\n",
       "Fees charged for closing account                                                          41\n",
       "Funds not handled or disbursed as instructed                                             250\n",
       "Funds not received from closed account                                                   107\n",
       "Information belongs to someone else                                                        7\n",
       "Late or other fees                                                                        22\n",
       "Money was taken from your account on the wrong day or for the wrong amount                67\n",
       "Non-sufficient funds and associated fees                                                 133\n",
       "Old information reappears or never goes away                                               1\n",
       "Other problem getting your report or credit score                                          2\n",
       "Overdrafts and overdraft fees                                                            372\n",
       "Problem accessing account                                                                183\n",
       "Problem canceling credit monitoring or identify theft protection service                   1\n",
       "Problem making or receiving payments                                                     160\n",
       "Problem using a debit or ATM card                                                        493\n",
       "Public record information inaccurate                                                       2\n",
       "Received unsolicited financial product or insurance offers after opting out                1\n",
       "Reporting company used your report improperly                                              4\n",
       "Their investigation did not fix an error on your report                                    1\n",
       "Transaction was not authorized                                                           420\n",
       "Unable to open an account                                                                182\n",
       "Was not notified of investigation status or results                                        1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.groupby(['sub_issue']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='4'>4. Random Forest</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part, we use the random forest method as a standard classification problem. We classify the complaints into the issues. In this part, we choose the number of topics as 10. Also, this number of topics can be tuned. For convenience, I didn't tune this parameter. But definitely this parameter is pretty important for the performance of the classification problem. If you want to get better performance, you definitely need to use cross validation method to choose the best parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rui/.local/lib/python3.5/site-packages/sklearn/decomposition/online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "n_features = 10\n",
    "\n",
    "lda = LatentDirichletAllocation(n_topics=n_features, max_iter=5, learning_method='online', learning_offset=64.,random_state=0).fit(tf_train)\n",
    "\n",
    "# words per topic\n",
    "lda_T = lda.components_\n",
    "# topics per document_\n",
    "lda_D_train = lda.transform(tf_train)\n",
    "lda_D_test = lda.transform(tf_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We choose the top 3 most likely predicted issues label according to the random forest prediction result. Then we save them in the \"predicted_issue\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state = 42)\n",
    "clf.fit(lda_D_train, X_train['issue'])\n",
    "y_categories = clf.classes_\n",
    "\n",
    "issue_preds = clf.predict_proba(lda_D_train)\n",
    "issue_predictions = np.array([\", \".join(y_categories[issue_pred.argsort()[-3:]]) for issue_pred in issue_preds])\n",
    "# print (y_categories)\n",
    "X_train[\"predicted_issue\"] = issue_predictions\n",
    "\n",
    "issue_preds = clf.predict_proba(lda_D_test)\n",
    "issue_predictions = np.array([\", \".join(y_categories[issue_pred.argsort()[-3:]]) for issue_pred in issue_preds])\n",
    "# print (y_categories)\n",
    "X_test[\"predicted_issue\"] = issue_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We show the predicted issue results here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>consumer_complaint_narrative</th>\n",
       "      <th>issue</th>\n",
       "      <th>sub_issue</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>predicted_issue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>849900</th>\n",
       "      <td>USBank allowed my ex husband to fraudulently o...</td>\n",
       "      <td>Opening an account</td>\n",
       "      <td>Account opened as a result of fraud</td>\n",
       "      <td>fraud,inform,branch,report,person</td>\n",
       "      <td>-0.069585</td>\n",
       "      <td>0.367512</td>\n",
       "      <td>Problem with a lender or other company chargin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967968</th>\n",
       "      <td>My husband and I have had a joint account at P...</td>\n",
       "      <td>Problem caused by your funds being low</td>\n",
       "      <td>Overdrafts and overdraft fees</td>\n",
       "      <td>fraud,inform,branch,report,person</td>\n",
       "      <td>0.016532</td>\n",
       "      <td>0.167742</td>\n",
       "      <td>Problem with a lender or other company chargin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907684</th>\n",
       "      <td>My personal check was refused at XXXX XXXX eve...</td>\n",
       "      <td>Managing an account</td>\n",
       "      <td>Problem making or receiving payments</td>\n",
       "      <td>get,back,said,call,tri</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>Problem with a lender or other company chargin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971822</th>\n",
       "      <td>It 's beyond any human being to imagine the to...</td>\n",
       "      <td>Closing an account</td>\n",
       "      <td>Funds not received from closed account</td>\n",
       "      <td>get,back,said,call,tri</td>\n",
       "      <td>0.028432</td>\n",
       "      <td>0.452938</td>\n",
       "      <td>Closing an account, Problem with a lender or o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938113</th>\n",
       "      <td>I lodged a complaint few days back to CFPB. Th...</td>\n",
       "      <td>Managing an account</td>\n",
       "      <td>Banking errors</td>\n",
       "      <td>deposit,direct,bonu,branch,receiv</td>\n",
       "      <td>-0.111111</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>Closing an account, Managing an account, Openi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             consumer_complaint_narrative  \\\n",
       "849900  USBank allowed my ex husband to fraudulently o...   \n",
       "967968  My husband and I have had a joint account at P...   \n",
       "907684  My personal check was refused at XXXX XXXX eve...   \n",
       "971822  It 's beyond any human being to imagine the to...   \n",
       "938113  I lodged a complaint few days back to CFPB. Th...   \n",
       "\n",
       "                                         issue  \\\n",
       "849900                      Opening an account   \n",
       "967968  Problem caused by your funds being low   \n",
       "907684                     Managing an account   \n",
       "971822                      Closing an account   \n",
       "938113                     Managing an account   \n",
       "\n",
       "                                     sub_issue  \\\n",
       "849900     Account opened as a result of fraud   \n",
       "967968           Overdrafts and overdraft fees   \n",
       "907684    Problem making or receiving payments   \n",
       "971822  Funds not received from closed account   \n",
       "938113                          Banking errors   \n",
       "\n",
       "                                    Topic  Polarity  Subjectivity  \\\n",
       "849900  fraud,inform,branch,report,person -0.069585      0.367512   \n",
       "967968  fraud,inform,branch,report,person  0.016532      0.167742   \n",
       "907684             get,back,said,call,tri -0.133333      0.333333   \n",
       "971822             get,back,said,call,tri  0.028432      0.452938   \n",
       "938113  deposit,direct,bonu,branch,receiv -0.111111      0.355556   \n",
       "\n",
       "                                          predicted_issue  \n",
       "849900  Problem with a lender or other company chargin...  \n",
       "967968  Problem with a lender or other company chargin...  \n",
       "907684  Problem with a lender or other company chargin...  \n",
       "971822  Closing an account, Problem with a lender or o...  \n",
       "938113  Closing an account, Managing an account, Openi...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute accuracy of prediction. we find that if we choose top three likely predicted issue, it has 90.1% probability that the true issue is belong to the predicted issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select one results, accuracy: 0.1186046511627907\n",
      "Select two results, accuracy: 0.3732558139534884\n",
      "Select three results, accuracy: 0.9011627906976745\n"
     ]
    }
   ],
   "source": [
    "num_matched = 0\n",
    "for i in range(X_test.shape[0]):\n",
    "    if X_test.iloc[i, 1] in X_test.iloc[i, -1].split(\", \")[:1]:\n",
    "        num_matched += 1\n",
    "# print(num_matched)\n",
    "print (\"Select one results, accuracy: {}\".format(num_matched/X_test.shape[0]))\n",
    "num_matched = 0\n",
    "for i in range(X_test.shape[0]):\n",
    "    if X_test.iloc[i, 1] in X_test.iloc[i, -1].split(\", \")[:2]:\n",
    "        num_matched += 1\n",
    "# print(num_matched)\n",
    "print (\"Select two results, accuracy: {}\".format(num_matched/X_test.shape[0]))\n",
    "num_matched = 0\n",
    "for i in range(X_test.shape[0]):\n",
    "    if X_test.iloc[i, 1] in X_test.iloc[i, -1].split(\", \")[:3]:\n",
    "        num_matched += 1\n",
    "# print(num_matched)\n",
    "print (\"Select three results, accuracy: {}\".format(num_matched/X_test.shape[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
